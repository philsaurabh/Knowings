{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Copy of supervised-contrastive-learning","provenance":[{"file_id":"https://github.com/keras-team/keras-io/blob/master/examples/vision/ipynb/supervised-contrastive-learning.ipynb","timestamp":1623669110935}],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.0"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"NNQsiTJFGytO","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1623691932704,"user_tz":-330,"elapsed":3012,"user":{"displayName":"SAURABH SHARMA","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhB3dg8ZOcriaGgsxpLQf3hNobKQCow8yIKwSndGA=s64","userId":"06441528299044093819"}},"outputId":"636b75cf-d614-4f2e-89d5-07352b238b11"},"source":["! pip install tensorflow-addons"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Collecting tensorflow-addons\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/66/4b/e893d194e626c24b3df2253066aa418f46a432fdb68250cde14bf9bb0700/tensorflow_addons-0.13.0-cp37-cp37m-manylinux2010_x86_64.whl (679kB)\n","\r\u001b[K     |▌                               | 10kB 16.3MB/s eta 0:00:01\r\u001b[K     |█                               | 20kB 23.2MB/s eta 0:00:01\r\u001b[K     |█▌                              | 30kB 24.7MB/s eta 0:00:01\r\u001b[K     |██                              | 40kB 22.5MB/s eta 0:00:01\r\u001b[K     |██▍                             | 51kB 21.6MB/s eta 0:00:01\r\u001b[K     |███                             | 61kB 23.8MB/s eta 0:00:01\r\u001b[K     |███▍                            | 71kB 21.5MB/s eta 0:00:01\r\u001b[K     |███▉                            | 81kB 22.7MB/s eta 0:00:01\r\u001b[K     |████▍                           | 92kB 23.7MB/s eta 0:00:01\r\u001b[K     |████▉                           | 102kB 24.2MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 112kB 24.2MB/s eta 0:00:01\r\u001b[K     |█████▉                          | 122kB 24.2MB/s eta 0:00:01\r\u001b[K     |██████▎                         | 133kB 24.2MB/s eta 0:00:01\r\u001b[K     |██████▊                         | 143kB 24.2MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 153kB 24.2MB/s eta 0:00:01\r\u001b[K     |███████▊                        | 163kB 24.2MB/s eta 0:00:01\r\u001b[K     |████████▏                       | 174kB 24.2MB/s eta 0:00:01\r\u001b[K     |████████▊                       | 184kB 24.2MB/s eta 0:00:01\r\u001b[K     |█████████▏                      | 194kB 24.2MB/s eta 0:00:01\r\u001b[K     |█████████▋                      | 204kB 24.2MB/s eta 0:00:01\r\u001b[K     |██████████▏                     | 215kB 24.2MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 225kB 24.2MB/s eta 0:00:01\r\u001b[K     |███████████                     | 235kB 24.2MB/s eta 0:00:01\r\u001b[K     |███████████▋                    | 245kB 24.2MB/s eta 0:00:01\r\u001b[K     |████████████                    | 256kB 24.2MB/s eta 0:00:01\r\u001b[K     |████████████▌                   | 266kB 24.2MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 276kB 24.2MB/s eta 0:00:01\r\u001b[K     |█████████████▌                  | 286kB 24.2MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 296kB 24.2MB/s eta 0:00:01\r\u001b[K     |██████████████▌                 | 307kB 24.2MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 317kB 24.2MB/s eta 0:00:01\r\u001b[K     |███████████████▍                | 327kB 24.2MB/s eta 0:00:01\r\u001b[K     |████████████████                | 337kB 24.2MB/s eta 0:00:01\r\u001b[K     |████████████████▍               | 348kB 24.2MB/s eta 0:00:01\r\u001b[K     |████████████████▉               | 358kB 24.2MB/s eta 0:00:01\r\u001b[K     |█████████████████▍              | 368kB 24.2MB/s eta 0:00:01\r\u001b[K     |█████████████████▉              | 378kB 24.2MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 389kB 24.2MB/s eta 0:00:01\r\u001b[K     |██████████████████▉             | 399kB 24.2MB/s eta 0:00:01\r\u001b[K     |███████████████████▎            | 409kB 24.2MB/s eta 0:00:01\r\u001b[K     |███████████████████▊            | 419kB 24.2MB/s eta 0:00:01\r\u001b[K     |████████████████████▎           | 430kB 24.2MB/s eta 0:00:01\r\u001b[K     |████████████████████▊           | 440kB 24.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 450kB 24.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████▊          | 460kB 24.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████▏         | 471kB 24.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████▋         | 481kB 24.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████▏        | 491kB 24.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████▋        | 501kB 24.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 512kB 24.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████▋       | 522kB 24.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 532kB 24.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▌      | 542kB 24.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 552kB 24.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 563kB 24.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 573kB 24.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▌    | 583kB 24.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 593kB 24.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▍   | 604kB 24.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 614kB 24.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▍  | 624kB 24.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▉  | 634kB 24.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▍ | 645kB 24.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 655kB 24.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▎| 665kB 24.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▉| 675kB 24.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 686kB 24.2MB/s \n","\u001b[?25hRequirement already satisfied: typeguard>=2.7 in /usr/local/lib/python3.7/dist-packages (from tensorflow-addons) (2.7.1)\n","Installing collected packages: tensorflow-addons\n","Successfully installed tensorflow-addons-0.13.0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"LHx6VC_xGuGa","executionInfo":{"status":"ok","timestamp":1623691934331,"user_tz":-330,"elapsed":1630,"user":{"displayName":"SAURABH SHARMA","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhB3dg8ZOcriaGgsxpLQf3hNobKQCow8yIKwSndGA=s64","userId":"06441528299044093819"}}},"source":["import tensorflow as tf\n","import tensorflow_addons as tfa\n","import numpy as np\n","from tensorflow import keras\n","from tensorflow.keras import layers"],"execution_count":2,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"7hozhOK_GuGb"},"source":["## Prepare the data"]},{"cell_type":"code","metadata":{"id":"KgyltXY5GuGb","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1623691941157,"user_tz":-330,"elapsed":6834,"user":{"displayName":"SAURABH SHARMA","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhB3dg8ZOcriaGgsxpLQf3hNobKQCow8yIKwSndGA=s64","userId":"06441528299044093819"}},"outputId":"13388489-74f2-40e2-c6d5-d3fcce01069e"},"source":["num_classes = 10\n","input_shape = (32, 32, 3)\n","\n","# Load the train and test data splits\n","(x_train, y_train), (x_test, y_test) = keras.datasets.cifar10.load_data()\n","\n","# Display shapes of train and test datasets\n","print(f\"x_train shape: {x_train.shape} - y_train shape: {y_train.shape}\")\n","print(f\"x_test shape: {x_test.shape} - y_test shape: {y_test.shape}\")\n"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n","170500096/170498071 [==============================] - 5s 0us/step\n","x_train shape: (50000, 32, 32, 3) - y_train shape: (50000, 1)\n","x_test shape: (10000, 32, 32, 3) - y_test shape: (10000, 1)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"2GGJ6eijGuGc"},"source":["## Using image data augmentation"]},{"cell_type":"code","metadata":{"id":"pPRxT0VXGuGc","executionInfo":{"status":"ok","timestamp":1623691948091,"user_tz":-330,"elapsed":6953,"user":{"displayName":"SAURABH SHARMA","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhB3dg8ZOcriaGgsxpLQf3hNobKQCow8yIKwSndGA=s64","userId":"06441528299044093819"}}},"source":["data_augmentation = keras.Sequential(\n","    [\n","        layers.experimental.preprocessing.Normalization(),\n","        layers.experimental.preprocessing.RandomFlip(\"horizontal\"),\n","        layers.experimental.preprocessing.RandomRotation(0.02),\n","        layers.experimental.preprocessing.RandomWidth(0.2),\n","        layers.experimental.preprocessing.RandomHeight(0.2),\n","    ]\n",")\n","\n","# Setting the state of the normalization layer.\n","data_augmentation.layers[0].adapt(x_train)"],"execution_count":4,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"tNuU7KngGuGd"},"source":["## Build the encoder model\n","\n","The encoder model takes the image as input and turns it into a 2048-dimensional\n","feature vector."]},{"cell_type":"code","metadata":{"id":"HuobPxmvGuGd","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1623691949513,"user_tz":-330,"elapsed":1425,"user":{"displayName":"SAURABH SHARMA","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhB3dg8ZOcriaGgsxpLQf3hNobKQCow8yIKwSndGA=s64","userId":"06441528299044093819"}},"outputId":"5a6429e1-344e-4979-d75d-3343bc985a0b"},"source":["\n","def create_encoder():\n","    resnet = keras.applications.ResNet50V2(\n","        include_top=False, weights=None, input_shape=input_shape, pooling=\"avg\"\n","    )\n","\n","    inputs = keras.Input(shape=input_shape)\n","    augmented = data_augmentation(inputs)\n","    outputs = resnet(augmented)\n","    model = keras.Model(inputs=inputs, outputs=outputs, name=\"cifar10-encoder\")\n","    return model\n","\n","\n","encoder = create_encoder()\n","encoder.summary()\n","\n","learning_rate = 0.001\n","batch_size = 265\n","hidden_units = 512\n","projection_units = 128\n","num_epochs = 1\n","dropout_rate = 0.5\n","temperature = 0.05"],"execution_count":5,"outputs":[{"output_type":"stream","text":["Model: \"cifar10-encoder\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","input_2 (InputLayer)         [(None, 32, 32, 3)]       0         \n","_________________________________________________________________\n","sequential (Sequential)      (None, None, None, 3)     7         \n","_________________________________________________________________\n","resnet50v2 (Functional)      (None, 2048)              23564800  \n","=================================================================\n","Total params: 23,564,807\n","Trainable params: 23,519,360\n","Non-trainable params: 45,447\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"J_dmJqf2lNzA","executionInfo":{"status":"ok","timestamp":1623692171006,"user_tz":-330,"elapsed":981,"user":{"displayName":"SAURABH SHARMA","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhB3dg8ZOcriaGgsxpLQf3hNobKQCow8yIKwSndGA=s64","userId":"06441528299044093819"}},"outputId":"c713faf1-deb8-43f9-f594-e70d4c98315e"},"source":["def create_encoder1():\n","    resnet = keras.applications.MobileNet(\n","        include_top=False, weights=None, input_shape=input_shape, pooling=\"avg\"\n","    )\n","\n","    inputs = keras.Input(shape=input_shape)\n","    augmented = data_augmentation(inputs)\n","    outputs = resnet(augmented)\n","    model = keras.Model(inputs=inputs, outputs=outputs, name=\"cifar10-encoder1\")\n","    return model\n","\n","\n","encoder1 = create_encoder1()\n","encoder1.summary()"],"execution_count":6,"outputs":[{"output_type":"stream","text":["Model: \"cifar10-encoder1\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","input_4 (InputLayer)         [(None, 32, 32, 3)]       0         \n","_________________________________________________________________\n","sequential (Sequential)      (None, None, None, 3)     7         \n","_________________________________________________________________\n","mobilenet_1.00_32 (Functiona (None, 1024)              3228864   \n","=================================================================\n","Total params: 3,228,871\n","Trainable params: 3,206,976\n","Non-trainable params: 21,895\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"u3YONuHDGuGe"},"source":["## Build the classification model\n","\n","The classification model adds a fully-connected layer on top of the encoder,\n","plus a softmax layer with the target classes."]},{"cell_type":"code","metadata":{"id":"NkFomeEHGuGe","executionInfo":{"status":"ok","timestamp":1623692176116,"user_tz":-330,"elapsed":371,"user":{"displayName":"SAURABH SHARMA","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhB3dg8ZOcriaGgsxpLQf3hNobKQCow8yIKwSndGA=s64","userId":"06441528299044093819"}}},"source":["\n","def create_classifier(encoder, trainable=True):\n","\n","    for layer in encoder.layers:\n","        layer.trainable = trainable\n","\n","    inputs = keras.Input(shape=input_shape)\n","    features = encoder(inputs)\n","    features = layers.Dropout(dropout_rate)(features)\n","    features = layers.Dense(hidden_units, activation=\"relu\")(features)\n","    features = layers.Dropout(dropout_rate)(features)\n","    outputs = layers.Dense(num_classes, activation=\"softmax\")(features)\n","\n","    model = keras.Model(inputs=inputs, outputs=outputs, name=\"cifar10-classifier\")\n","    model.compile(\n","        optimizer=keras.optimizers.Adam(learning_rate),\n","        loss=keras.losses.SparseCategoricalCrossentropy(),\n","        metrics=[keras.metrics.SparseCategoricalAccuracy()],\n","    )\n","    return model\n"],"execution_count":7,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"4jgiXuBQGuGf"},"source":["## Experiment 1: Train the baseline classification model\n","\n","In this experiment, a baseline classifier is trained as usual, i.e., the\n","encoder and the classifier parts are trained together as a single model\n","to minimize the crossentropy loss."]},{"cell_type":"code","metadata":{"id":"vRG2gSetGuGf","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1623668624719,"user_tz":-330,"elapsed":103647,"user":{"displayName":"","photoUrl":"","userId":""}},"outputId":"e9efad05-da83-4941-b715-5cd1ba5571ef"},"source":["encoder = create_encoder()\n","classifier = create_classifier(encoder)\n","classifier.summary()\n","\n","history = classifier.fit(x=x_train, y=y_train, batch_size=batch_size, epochs=num_epochs)\n","\n","accuracy = classifier.evaluate(x_test, y_test)[1]\n","print(f\"Test accuracy: {round(accuracy * 100, 2)}%\")\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Model: \"cifar10-classifier\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","input_5 (InputLayer)         [(None, 32, 32, 3)]       0         \n","_________________________________________________________________\n","cifar10-encoder (Functional) (None, 2048)              23564807  \n","_________________________________________________________________\n","dropout (Dropout)            (None, 2048)              0         \n","_________________________________________________________________\n","dense (Dense)                (None, 512)               1049088   \n","_________________________________________________________________\n","dropout_1 (Dropout)          (None, 512)               0         \n","_________________________________________________________________\n","dense_1 (Dense)              (None, 10)                5130      \n","=================================================================\n","Total params: 24,619,025\n","Trainable params: 24,573,578\n","Non-trainable params: 45,447\n","_________________________________________________________________\n","189/189 [==============================] - 90s 407ms/step - loss: 1.9455 - sparse_categorical_accuracy: 0.2769\n","313/313 [==============================] - 10s 26ms/step - loss: 2.1547 - sparse_categorical_accuracy: 0.2588\n","Test accuracy: 25.88%\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"r9tJ7fcqGuGg"},"source":["## Experiment 2: Use supervised contrastive learning\n","\n","In this experiment, the model is trained in two phases. In the first phase,\n","the encoder is pretrained to optimize the supervised contrastive loss,\n","described in [Prannay Khosla et al.](https://arxiv.org/abs/2004.11362).\n","\n","In the second phase, the classifier is trained using the trained encoder with\n","its weights freezed; only the weights of fully-connected layers with the\n","softmax are optimized.\n","\n","### 1. Supervised contrastive learning loss function"]},{"cell_type":"code","metadata":{"id":"Pu--qV68GuGg","executionInfo":{"status":"ok","timestamp":1623693025072,"user_tz":-330,"elapsed":376,"user":{"displayName":"SAURABH SHARMA","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhB3dg8ZOcriaGgsxpLQf3hNobKQCow8yIKwSndGA=s64","userId":"06441528299044093819"}}},"source":["\n","class SupervisedContrastiveLoss(keras.losses.Loss):\n","    def __init__(self, temperature=1, name=None):\n","        super(SupervisedContrastiveLoss, self).__init__(name=name)\n","        self.temperature = temperature\n","\n","    def __call__(self, labels, feature_vectors, sample_weight=None):\n","        # Normalize feature vectors\n","        feature_vectors_normalized = tf.math.l2_normalize(feature_vectors, axis=1)\n","        # Compute logits\n","        logits = tf.divide(\n","            tf.matmul(\n","                feature_vectors_normalized, tf.transpose(feature_vectors_normalized)\n","            ),\n","            self.temperature,\n","        )\n","        return tfa.losses.npairs_loss(tf.squeeze(labels), logits)\n","\n","\n","def add_projection_head(encoder):\n","    inputs = keras.Input(shape=input_shape)\n","    features = encoder(inputs)\n","    outputs = layers.Dense(projection_units, activation=\"softmax\")(features)\n","    model = keras.Model(\n","        inputs=inputs, outputs=outputs, name=\"cifar-encoder_with_projection-head\"\n","    )\n","    return model\n"],"execution_count":30,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"vh39yfBsGuGh"},"source":["### 2. Pretrain the encoder"]},{"cell_type":"code","metadata":{"id":"e0aHXhj5GuGh","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1623692295839,"user_tz":-330,"elapsed":102775,"user":{"displayName":"SAURABH SHARMA","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhB3dg8ZOcriaGgsxpLQf3hNobKQCow8yIKwSndGA=s64","userId":"06441528299044093819"}},"outputId":"4d7ea403-1a5a-4592-fccf-1382579a4ef3"},"source":["encoder = create_encoder()\n","\n","encoder_with_projection_head = add_projection_head(encoder)\n","encoder_with_projection_head.compile(\n","    optimizer=keras.optimizers.Adam(learning_rate),\n","    loss=SupervisedContrastiveLoss(temperature),\n",")\n","\n","encoder_with_projection_head.summary()\n","student_scratch = keras.models.clone_model(encoder_with_projection_head)\n","history = encoder_with_projection_head.fit(\n","    x=x_train, y=y_train, batch_size=batch_size, epochs=num_epochs\n",")"],"execution_count":9,"outputs":[{"output_type":"stream","text":["Model: \"cifar-encoder_with_projection-head\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","input_7 (InputLayer)         [(None, 32, 32, 3)]       0         \n","_________________________________________________________________\n","cifar10-encoder (Functional) (None, 2048)              23564807  \n","_________________________________________________________________\n","dense (Dense)                (None, 128)               262272    \n","=================================================================\n","Total params: 23,827,079\n","Trainable params: 23,781,632\n","Non-trainable params: 45,447\n","_________________________________________________________________\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/utils/generic_utils.py:497: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n","  category=CustomMaskWarning)\n"],"name":"stderr"},{"output_type":"stream","text":["189/189 [==============================] - 98s 303ms/step - loss: 5.3842\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pRA6KpTGmMDn","executionInfo":{"status":"ok","timestamp":1623693033484,"user_tz":-330,"elapsed":2497,"user":{"displayName":"SAURABH SHARMA","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhB3dg8ZOcriaGgsxpLQf3hNobKQCow8yIKwSndGA=s64","userId":"06441528299044093819"}},"outputId":"82d205a2-b945-469a-f30c-d66c4c0b3404"},"source":["encoder = create_encoder1()\n","\n","encoder_with_projection_head1 = add_projection_head(encoder1)\n","encoder_with_projection_head1.compile(\n","    optimizer=keras.optimizers.Adam(learning_rate),\n","    loss=SupervisedContrastiveLoss(temperature),\n",")\n","\n","encoder_with_projection_head1.summary()\n","student_scratch1 = keras.models.clone_model(encoder_with_projection_head1)"],"execution_count":31,"outputs":[{"output_type":"stream","text":["Model: \"cifar-encoder_with_projection-head\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","input_14 (InputLayer)        [(None, 32, 32, 3)]       0         \n","_________________________________________________________________\n","cifar10-encoder1 (Functional (None, 1024)              3228871   \n","_________________________________________________________________\n","dense_4 (Dense)              (None, 128)               131200    \n","=================================================================\n","Total params: 3,360,071\n","Trainable params: 3,338,176\n","Non-trainable params: 21,895\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"2tACTm3qHK77","executionInfo":{"status":"ok","timestamp":1623693036795,"user_tz":-330,"elapsed":363,"user":{"displayName":"SAURABH SHARMA","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhB3dg8ZOcriaGgsxpLQf3hNobKQCow8yIKwSndGA=s64","userId":"06441528299044093819"}}},"source":["class Distiller(keras.Model):\n","    def __init__(self, student, teacher):\n","        super(Distiller, self).__init__()\n","        self.teacher = teacher\n","        self.student = student\n","\n","    def compile(\n","        self,\n","        optimizer,\n","        metrics,\n","        student_loss_fn,\n","        distillation_loss_fn,\n","        alpha=0.1,\n","        temperature=3,\n","    ):\n","        \"\"\" Configure the distiller.\n","\n","        Args:\n","            optimizer: Keras optimizer for the student weights\n","            metrics: Keras metrics for evaluation\n","            student_loss_fn: Loss function of difference between student\n","                predictions and ground-truth\n","            distillation_loss_fn: Loss function of difference between soft\n","                student predictions and soft teacher predictions\n","            alpha: weight to student_loss_fn and 1-alpha to distillation_loss_fn\n","            temperature: Temperature for softening probability distributions.\n","                Larger temperature gives softer distributions.\n","        \"\"\"\n","        super(Distiller, self).compile(optimizer=optimizer, metrics=metrics)\n","        self.student_loss_fn = student_loss_fn\n","        self.distillation_loss_fn = distillation_loss_fn\n","        self.alpha = alpha\n","        self.temperature = temperature\n","\n","    def train_step(self, data):\n","        # Unpack data\n","        x, y = data\n","\n","        # Forward pass of teacher\n","        teacher_predictions = self.teacher(x, training=False)\n","\n","        with tf.GradientTape() as tape:\n","            # Forward pass of student\n","            student_predictions = self.student(x, training=True)\n","\n","            # Compute losses\n","            student_loss = self.student_loss_fn(y, student_predictions)\n","            distillation_loss = self.distillation_loss_fn(\n","                tf.nn.softmax(teacher_predictions / self.temperature, axis=1),\n","                tf.nn.softmax(student_predictions / self.temperature, axis=1),\n","            )\n","            loss = self.alpha * student_loss + (1 - self.alpha) * distillation_loss\n","\n","        # Compute gradients\n","        trainable_vars = self.student.trainable_variables\n","        gradients = tape.gradient(loss, trainable_vars)\n","\n","        # Update weights\n","        self.optimizer.apply_gradients(zip(gradients, trainable_vars))\n","\n","        # Update the metrics configured in `compile()`.\n","        self.compiled_metrics.update_state(y, student_predictions)\n","\n","        # Return a dict of performance\n","        results = {m.name: m.result() for m in self.metrics}\n","        results.update(\n","            {\"student_loss\": student_loss, \"distillation_loss\": distillation_loss}\n","        )\n","        return results\n","\n","    def test_step(self, data):\n","        # Unpack the data\n","        x, y = data\n","\n","        # Compute predictions\n","        y_prediction = self.student(x, training=False)\n","\n","        # Calculate the loss\n","        student_loss = self.student_loss_fn(y, y_prediction)\n","\n","        # Update the metrics.\n","        self.compiled_metrics.update_state(y, y_prediction)\n","\n","        # Return a dict of performance\n","        results = {m.name: m.result() for m in self.metrics}\n","        results.update({\"student_loss\": student_loss})\n","        return results\n"],"execution_count":32,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kJa5CeTLmvpw","executionInfo":{"status":"ok","timestamp":1623693040555,"user_tz":-330,"elapsed":360,"user":{"displayName":"SAURABH SHARMA","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhB3dg8ZOcriaGgsxpLQf3hNobKQCow8yIKwSndGA=s64","userId":"06441528299044093819"}},"outputId":"32c33f40-edb7-4317-eaca-2890e832b4c1"},"source":["encoder_with_projection_head1.summary()"],"execution_count":33,"outputs":[{"output_type":"stream","text":["Model: \"cifar-encoder_with_projection-head\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","input_14 (InputLayer)        [(None, 32, 32, 3)]       0         \n","_________________________________________________________________\n","cifar10-encoder1 (Functional (None, 1024)              3228871   \n","_________________________________________________________________\n","dense_4 (Dense)              (None, 128)               131200    \n","=================================================================\n","Total params: 3,360,071\n","Trainable params: 3,338,176\n","Non-trainable params: 21,895\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"834IMCFLHSLd","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1623693187047,"user_tz":-330,"elapsed":145177,"user":{"displayName":"SAURABH SHARMA","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhB3dg8ZOcriaGgsxpLQf3hNobKQCow8yIKwSndGA=s64","userId":"06441528299044093819"}},"outputId":"f6189685-bad3-4235-898c-ecb02d6f89c9"},"source":["distiller = Distiller(student=encoder_with_projection_head1, teacher=encoder_with_projection_head)\n","distiller.compile(\n","    optimizer=keras.optimizers.Adam(),\n","    metrics=[keras.metrics.SparseCategoricalAccuracy()],\n","    student_loss_fn=keras.losses.SparseCategoricalCrossentropy(),\n","    distillation_loss_fn=keras.losses.KLDivergence(),\n","    alpha=0.1,\n","    temperature=10,\n",")\n","\n","# Distill teacher to student\n","distiller.fit(x_train, y_train, epochs=1, batch_size=32)\n","\n","# Evaluate student on test dataset\n","distiller.evaluate(x_test, y_test, batch_size=32)"],"execution_count":34,"outputs":[{"output_type":"stream","text":["1563/1563 [==============================] - 107s 30ms/step - sparse_categorical_accuracy: 0.1000 - student_loss: nan - distillation_loss: nan\n","313/313 [==============================] - 3s 7ms/step - sparse_categorical_accuracy: 0.1000 - student_loss: nan\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["[0.10000000149011612, nan]"]},"metadata":{"tags":[]},"execution_count":34}]},{"cell_type":"code","metadata":{"id":"i9z7IsiGNfaL","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1623692759380,"user_tz":-330,"elapsed":375,"user":{"displayName":"SAURABH SHARMA","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhB3dg8ZOcriaGgsxpLQf3hNobKQCow8yIKwSndGA=s64","userId":"06441528299044093819"}},"outputId":"93b819a8-2f7a-4e65-9e33-632af6674e1a"},"source":["distiller.layers[1].summary()"],"execution_count":20,"outputs":[{"output_type":"stream","text":["Model: \"cifar-encoder_with_projection-head\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","input_10 (InputLayer)        [(None, 32, 32, 3)]       0         \n","_________________________________________________________________\n","cifar10-encoder1 (Functional (None, 1024)              3228871   \n","_________________________________________________________________\n","dense_1 (Dense)              (None, 128)               131200    \n","=================================================================\n","Total params: 3,360,071\n","Trainable params: 3,338,176\n","Non-trainable params: 21,895\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"b6epTLBsKaY0","executionInfo":{"status":"ok","timestamp":1623692781291,"user_tz":-330,"elapsed":357,"user":{"displayName":"SAURABH SHARMA","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhB3dg8ZOcriaGgsxpLQf3hNobKQCow8yIKwSndGA=s64","userId":"06441528299044093819"}}},"source":["student_weight=distiller.layers[1].get_weights()\n","student_scratch1.set_weights(student_weight)"],"execution_count":23,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"1L19ovq8GuGh"},"source":["### 3. Train the classifier with the frozen encoder"]},{"cell_type":"code","metadata":{"id":"qEWEz3kNGuGi","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1623692797865,"user_tz":-330,"elapsed":11247,"user":{"displayName":"SAURABH SHARMA","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhB3dg8ZOcriaGgsxpLQf3hNobKQCow8yIKwSndGA=s64","userId":"06441528299044093819"}},"outputId":"ca4d4352-aed5-4dc2-8a27-d8b447bedcc6"},"source":["classifier = create_classifier(student_scratch1, trainable=False)\n","\n","history = classifier.fit(x=x_train, y=y_train, batch_size=batch_size, epochs=num_epochs)\n","\n","accuracy = classifier.evaluate(x_test, y_test)[1]\n","print(f\"Test accuracy: {round(accuracy * 100, 2)}%\")"],"execution_count":24,"outputs":[{"output_type":"stream","text":["189/189 [==============================] - 7s 29ms/step - loss: nan - sparse_categorical_accuracy: 0.1000\n","313/313 [==============================] - 2s 6ms/step - loss: nan - sparse_categorical_accuracy: 0.1000\n","Test accuracy: 10.0%\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"vwIqtTqSGuGi"},"source":["We get to an improved test accuracy."]},{"cell_type":"markdown","metadata":{"id":"dys1IO6CGuGi"},"source":["## Conclusion\n","\n","As shown in the experiments, using the supervised contrastive learning technique\n","outperformed the conventional technique in terms of the test accuracy. Note that\n","the same training budget (i.e., number of epochs) was given to each technique.\n","Supervised contrastive learning pays off when the encoder involves a complex\n","architecture, like ResNet, and multi-class problems with many labels.\n","In addition, large batch sizes and multi-layer projection heads\n","improve its effectiveness. See the [Supervised Contrastive Learning](https://arxiv.org/abs/2004.11362)\n","paper for more details."]}]}